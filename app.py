

import multiprocessing
from transformers import AutoTokenizer

from config import config
from core import train, test, checkpoint_callback
from inference import inference

tokenizer = AutoTokenizer.from_pretrained(config.PRETRAINED_MODEL, 
                                          num_labels=20, 
                                          problem_type="multi_label_classification")

if __name__=="__main__": 
    multiprocessing.freeze_support()
    
    model = train(tokenizer)
    threshold = test(model, tokenizer)

    threshold = 0.8
    intents = inference('''Contact: ุณูุงู ูู ุงูุงู ุจูู ูุณุงูุฑุช ุฎุฑุฏู ฺฉ ุจุฑุงู ุงุฑุณุงู ูุดู ฺูู ุนุฌูู ุฏุงุฑู, User: ุณูุงู
ุงูุฏูุงุฑู ุฑูุฒ ุฎูุจ ุฑู ุณูพุฑ ฺฉุฑุฏู ุจุงุดุฏ๐ุฏุฑ ุฎุฏูุชุชููู, User: ูพุณ ุงุฒ ุฎุฑุฏ ู ุจุฑุฑุณ ุงุทูุงุนุงุช ุจูู ุดูุง ุฏุฑ ุตู ุตุฏูุฑ ูุฑุงุฑ ู ฺฏุฑู ู ู ุฏุฑ ุตูุฑุช ูุงุฒ ุจู ูพฺฏุฑ ู ุง ูุฌูุฏ ูุดฺฉู ุฏุฑ ุงุทูุงุนุงุช ููฺฉุงุฑุงู ุจุง ุดูุง ุชูุงุณ ูฺฏุฑูุฏ๐
ุชูุฌู ุฏุงุดุชู ุจุงุดุฏ ุฏุฑ ุตูุฑุช ฺฉู ุฎุฑุฏุชูู ูุจู ุงุฒ ุณุงุนุช 21 ุงูุฌุงู ุจุดู ู ูุดฺฉู ูุฌูุฏ ูุฏุงุดุชู ุจุงุดู ุจูุชูู ุตุงุฏุฑ ูุดู ๐
ุงฺฏุฑ ุจุฑุฑุณ ฺฉุฑุฏุฏ ู ุจู ูุชุฌู ุง ูุฑุณุฏุฏ ูู ูููุฌุง ุฏุฑ ุฎุฏูุชุชูู ูุณุชู ุ ููฺูู ูุชููู ุจุง ุดูุงุฑู 02191020345 ุชูุงุณ ุจฺฏุฑู ููฺฉุงุฑุงูููู ุฏุฑ ุฎุฏูุชุชูู ูุณุชู ๐''', tokenizer, checkpoint_callback, threshold)

